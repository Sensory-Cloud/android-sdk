// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: v1/audio/audio.proto

package io.sensory.api.v1.audio;

/**
 * <pre>
 * Response from a TranscribeRequest
 * </pre>
 *
 * Protobuf type {@code sensory.api.v1.audio.TranscribeResponse}
 */
public  final class TranscribeResponse extends
    com.google.protobuf.GeneratedMessageLite<
        TranscribeResponse, TranscribeResponse.Builder> implements
    // @@protoc_insertion_point(message_implements:sensory.api.v1.audio.TranscribeResponse)
    TranscribeResponseOrBuilder {
  private TranscribeResponse() {
    transcript_ = "";
  }
  public static final int AUDIOENERGY_FIELD_NUMBER = 1;
  private float audioEnergy_;
  /**
   * <pre>
   * Relative energy of the processed audio as a value between 0 and 1
   * </pre>
   *
   * <code>float audioEnergy = 1;</code>
   * @return The audioEnergy.
   */
  @java.lang.Override
  public float getAudioEnergy() {
    return audioEnergy_;
  }
  /**
   * <pre>
   * Relative energy of the processed audio as a value between 0 and 1
   * </pre>
   *
   * <code>float audioEnergy = 1;</code>
   * @param value The audioEnergy to set.
   */
  private void setAudioEnergy(float value) {
    
    audioEnergy_ = value;
  }
  /**
   * <pre>
   * Relative energy of the processed audio as a value between 0 and 1
   * </pre>
   *
   * <code>float audioEnergy = 1;</code>
   */
  private void clearAudioEnergy() {
    
    audioEnergy_ = 0F;
  }

  public static final int TRANSCRIPT_FIELD_NUMBER = 2;
  private java.lang.String transcript_;
  /**
   * <pre>
   * Text of the current transcript
   * </pre>
   *
   * <code>string transcript = 2;</code>
   * @return The transcript.
   */
  @java.lang.Override
  public java.lang.String getTranscript() {
    return transcript_;
  }
  /**
   * <pre>
   * Text of the current transcript
   * </pre>
   *
   * <code>string transcript = 2;</code>
   * @return The bytes for transcript.
   */
  @java.lang.Override
  public com.google.protobuf.ByteString
      getTranscriptBytes() {
    return com.google.protobuf.ByteString.copyFromUtf8(transcript_);
  }
  /**
   * <pre>
   * Text of the current transcript
   * </pre>
   *
   * <code>string transcript = 2;</code>
   * @param value The transcript to set.
   */
  private void setTranscript(
      java.lang.String value) {
    java.lang.Class<?> valueClass = value.getClass();
  
    transcript_ = value;
  }
  /**
   * <pre>
   * Text of the current transcript
   * </pre>
   *
   * <code>string transcript = 2;</code>
   */
  private void clearTranscript() {
    
    transcript_ = getDefaultInstance().getTranscript();
  }
  /**
   * <pre>
   * Text of the current transcript
   * </pre>
   *
   * <code>string transcript = 2;</code>
   * @param value The bytes for transcript to set.
   */
  private void setTranscriptBytes(
      com.google.protobuf.ByteString value) {
    checkByteStringIsUtf8(value);
    transcript_ = value.toStringUtf8();
    
  }

  public static final int ISPARTIALRESULT_FIELD_NUMBER = 3;
  private boolean isPartialResult_;
  /**
   * <pre>
   * Indicates if the returned transcript is an intermediate result
   * </pre>
   *
   * <code>bool isPartialResult = 3;</code>
   * @return The isPartialResult.
   */
  @java.lang.Override
  public boolean getIsPartialResult() {
    return isPartialResult_;
  }
  /**
   * <pre>
   * Indicates if the returned transcript is an intermediate result
   * </pre>
   *
   * <code>bool isPartialResult = 3;</code>
   * @param value The isPartialResult to set.
   */
  private void setIsPartialResult(boolean value) {
    
    isPartialResult_ = value;
  }
  /**
   * <pre>
   * Indicates if the returned transcript is an intermediate result
   * </pre>
   *
   * <code>bool isPartialResult = 3;</code>
   */
  private void clearIsPartialResult() {
    
    isPartialResult_ = false;
  }

  public static final int POSTPROCESSINGACTION_FIELD_NUMBER = 10;
  private io.sensory.api.v1.audio.AudioResponsePostProcessingAction postProcessingAction_;
  /**
   * <pre>
   * If a post processing audio action was requested, this will be populated with the specific
   * action that was completed along with the actionId optionally set by the client.
   * </pre>
   *
   * <code>.sensory.api.v1.audio.AudioResponsePostProcessingAction postProcessingAction = 10;</code>
   */
  @java.lang.Override
  public boolean hasPostProcessingAction() {
    return postProcessingAction_ != null;
  }
  /**
   * <pre>
   * If a post processing audio action was requested, this will be populated with the specific
   * action that was completed along with the actionId optionally set by the client.
   * </pre>
   *
   * <code>.sensory.api.v1.audio.AudioResponsePostProcessingAction postProcessingAction = 10;</code>
   */
  @java.lang.Override
  public io.sensory.api.v1.audio.AudioResponsePostProcessingAction getPostProcessingAction() {
    return postProcessingAction_ == null ? io.sensory.api.v1.audio.AudioResponsePostProcessingAction.getDefaultInstance() : postProcessingAction_;
  }
  /**
   * <pre>
   * If a post processing audio action was requested, this will be populated with the specific
   * action that was completed along with the actionId optionally set by the client.
   * </pre>
   *
   * <code>.sensory.api.v1.audio.AudioResponsePostProcessingAction postProcessingAction = 10;</code>
   */
  private void setPostProcessingAction(io.sensory.api.v1.audio.AudioResponsePostProcessingAction value) {
    value.getClass();
  postProcessingAction_ = value;
    
    }
  /**
   * <pre>
   * If a post processing audio action was requested, this will be populated with the specific
   * action that was completed along with the actionId optionally set by the client.
   * </pre>
   *
   * <code>.sensory.api.v1.audio.AudioResponsePostProcessingAction postProcessingAction = 10;</code>
   */
  @java.lang.SuppressWarnings({"ReferenceEquality"})
  private void mergePostProcessingAction(io.sensory.api.v1.audio.AudioResponsePostProcessingAction value) {
    value.getClass();
  if (postProcessingAction_ != null &&
        postProcessingAction_ != io.sensory.api.v1.audio.AudioResponsePostProcessingAction.getDefaultInstance()) {
      postProcessingAction_ =
        io.sensory.api.v1.audio.AudioResponsePostProcessingAction.newBuilder(postProcessingAction_).mergeFrom(value).buildPartial();
    } else {
      postProcessingAction_ = value;
    }
    
  }
  /**
   * <pre>
   * If a post processing audio action was requested, this will be populated with the specific
   * action that was completed along with the actionId optionally set by the client.
   * </pre>
   *
   * <code>.sensory.api.v1.audio.AudioResponsePostProcessingAction postProcessingAction = 10;</code>
   */
  private void clearPostProcessingAction() {  postProcessingAction_ = null;
    
  }

  public static io.sensory.api.v1.audio.TranscribeResponse parseFrom(
      java.nio.ByteBuffer data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, data);
  }
  public static io.sensory.api.v1.audio.TranscribeResponse parseFrom(
      java.nio.ByteBuffer data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, data, extensionRegistry);
  }
  public static io.sensory.api.v1.audio.TranscribeResponse parseFrom(
      com.google.protobuf.ByteString data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, data);
  }
  public static io.sensory.api.v1.audio.TranscribeResponse parseFrom(
      com.google.protobuf.ByteString data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, data, extensionRegistry);
  }
  public static io.sensory.api.v1.audio.TranscribeResponse parseFrom(byte[] data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, data);
  }
  public static io.sensory.api.v1.audio.TranscribeResponse parseFrom(
      byte[] data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, data, extensionRegistry);
  }
  public static io.sensory.api.v1.audio.TranscribeResponse parseFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, input);
  }
  public static io.sensory.api.v1.audio.TranscribeResponse parseFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, input, extensionRegistry);
  }
  public static io.sensory.api.v1.audio.TranscribeResponse parseDelimitedFrom(java.io.InputStream input)
      throws java.io.IOException {
    return parseDelimitedFrom(DEFAULT_INSTANCE, input);
  }
  public static io.sensory.api.v1.audio.TranscribeResponse parseDelimitedFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return parseDelimitedFrom(DEFAULT_INSTANCE, input, extensionRegistry);
  }
  public static io.sensory.api.v1.audio.TranscribeResponse parseFrom(
      com.google.protobuf.CodedInputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, input);
  }
  public static io.sensory.api.v1.audio.TranscribeResponse parseFrom(
      com.google.protobuf.CodedInputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, input, extensionRegistry);
  }

  public static Builder newBuilder() {
    return (Builder) DEFAULT_INSTANCE.createBuilder();
  }
  public static Builder newBuilder(io.sensory.api.v1.audio.TranscribeResponse prototype) {
    return (Builder) DEFAULT_INSTANCE.createBuilder(prototype);
  }

  /**
   * <pre>
   * Response from a TranscribeRequest
   * </pre>
   *
   * Protobuf type {@code sensory.api.v1.audio.TranscribeResponse}
   */
  public static final class Builder extends
      com.google.protobuf.GeneratedMessageLite.Builder<
        io.sensory.api.v1.audio.TranscribeResponse, Builder> implements
      // @@protoc_insertion_point(builder_implements:sensory.api.v1.audio.TranscribeResponse)
      io.sensory.api.v1.audio.TranscribeResponseOrBuilder {
    // Construct using io.sensory.api.v1.audio.TranscribeResponse.newBuilder()
    private Builder() {
      super(DEFAULT_INSTANCE);
    }


    /**
     * <pre>
     * Relative energy of the processed audio as a value between 0 and 1
     * </pre>
     *
     * <code>float audioEnergy = 1;</code>
     * @return The audioEnergy.
     */
    @java.lang.Override
    public float getAudioEnergy() {
      return instance.getAudioEnergy();
    }
    /**
     * <pre>
     * Relative energy of the processed audio as a value between 0 and 1
     * </pre>
     *
     * <code>float audioEnergy = 1;</code>
     * @param value The audioEnergy to set.
     * @return This builder for chaining.
     */
    public Builder setAudioEnergy(float value) {
      copyOnWrite();
      instance.setAudioEnergy(value);
      return this;
    }
    /**
     * <pre>
     * Relative energy of the processed audio as a value between 0 and 1
     * </pre>
     *
     * <code>float audioEnergy = 1;</code>
     * @return This builder for chaining.
     */
    public Builder clearAudioEnergy() {
      copyOnWrite();
      instance.clearAudioEnergy();
      return this;
    }

    /**
     * <pre>
     * Text of the current transcript
     * </pre>
     *
     * <code>string transcript = 2;</code>
     * @return The transcript.
     */
    @java.lang.Override
    public java.lang.String getTranscript() {
      return instance.getTranscript();
    }
    /**
     * <pre>
     * Text of the current transcript
     * </pre>
     *
     * <code>string transcript = 2;</code>
     * @return The bytes for transcript.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getTranscriptBytes() {
      return instance.getTranscriptBytes();
    }
    /**
     * <pre>
     * Text of the current transcript
     * </pre>
     *
     * <code>string transcript = 2;</code>
     * @param value The transcript to set.
     * @return This builder for chaining.
     */
    public Builder setTranscript(
        java.lang.String value) {
      copyOnWrite();
      instance.setTranscript(value);
      return this;
    }
    /**
     * <pre>
     * Text of the current transcript
     * </pre>
     *
     * <code>string transcript = 2;</code>
     * @return This builder for chaining.
     */
    public Builder clearTranscript() {
      copyOnWrite();
      instance.clearTranscript();
      return this;
    }
    /**
     * <pre>
     * Text of the current transcript
     * </pre>
     *
     * <code>string transcript = 2;</code>
     * @param value The bytes for transcript to set.
     * @return This builder for chaining.
     */
    public Builder setTranscriptBytes(
        com.google.protobuf.ByteString value) {
      copyOnWrite();
      instance.setTranscriptBytes(value);
      return this;
    }

    /**
     * <pre>
     * Indicates if the returned transcript is an intermediate result
     * </pre>
     *
     * <code>bool isPartialResult = 3;</code>
     * @return The isPartialResult.
     */
    @java.lang.Override
    public boolean getIsPartialResult() {
      return instance.getIsPartialResult();
    }
    /**
     * <pre>
     * Indicates if the returned transcript is an intermediate result
     * </pre>
     *
     * <code>bool isPartialResult = 3;</code>
     * @param value The isPartialResult to set.
     * @return This builder for chaining.
     */
    public Builder setIsPartialResult(boolean value) {
      copyOnWrite();
      instance.setIsPartialResult(value);
      return this;
    }
    /**
     * <pre>
     * Indicates if the returned transcript is an intermediate result
     * </pre>
     *
     * <code>bool isPartialResult = 3;</code>
     * @return This builder for chaining.
     */
    public Builder clearIsPartialResult() {
      copyOnWrite();
      instance.clearIsPartialResult();
      return this;
    }

    /**
     * <pre>
     * If a post processing audio action was requested, this will be populated with the specific
     * action that was completed along with the actionId optionally set by the client.
     * </pre>
     *
     * <code>.sensory.api.v1.audio.AudioResponsePostProcessingAction postProcessingAction = 10;</code>
     */
    @java.lang.Override
    public boolean hasPostProcessingAction() {
      return instance.hasPostProcessingAction();
    }
    /**
     * <pre>
     * If a post processing audio action was requested, this will be populated with the specific
     * action that was completed along with the actionId optionally set by the client.
     * </pre>
     *
     * <code>.sensory.api.v1.audio.AudioResponsePostProcessingAction postProcessingAction = 10;</code>
     */
    @java.lang.Override
    public io.sensory.api.v1.audio.AudioResponsePostProcessingAction getPostProcessingAction() {
      return instance.getPostProcessingAction();
    }
    /**
     * <pre>
     * If a post processing audio action was requested, this will be populated with the specific
     * action that was completed along with the actionId optionally set by the client.
     * </pre>
     *
     * <code>.sensory.api.v1.audio.AudioResponsePostProcessingAction postProcessingAction = 10;</code>
     */
    public Builder setPostProcessingAction(io.sensory.api.v1.audio.AudioResponsePostProcessingAction value) {
      copyOnWrite();
      instance.setPostProcessingAction(value);
      return this;
      }
    /**
     * <pre>
     * If a post processing audio action was requested, this will be populated with the specific
     * action that was completed along with the actionId optionally set by the client.
     * </pre>
     *
     * <code>.sensory.api.v1.audio.AudioResponsePostProcessingAction postProcessingAction = 10;</code>
     */
    public Builder setPostProcessingAction(
        io.sensory.api.v1.audio.AudioResponsePostProcessingAction.Builder builderForValue) {
      copyOnWrite();
      instance.setPostProcessingAction(builderForValue.build());
      return this;
    }
    /**
     * <pre>
     * If a post processing audio action was requested, this will be populated with the specific
     * action that was completed along with the actionId optionally set by the client.
     * </pre>
     *
     * <code>.sensory.api.v1.audio.AudioResponsePostProcessingAction postProcessingAction = 10;</code>
     */
    public Builder mergePostProcessingAction(io.sensory.api.v1.audio.AudioResponsePostProcessingAction value) {
      copyOnWrite();
      instance.mergePostProcessingAction(value);
      return this;
    }
    /**
     * <pre>
     * If a post processing audio action was requested, this will be populated with the specific
     * action that was completed along with the actionId optionally set by the client.
     * </pre>
     *
     * <code>.sensory.api.v1.audio.AudioResponsePostProcessingAction postProcessingAction = 10;</code>
     */
    public Builder clearPostProcessingAction() {  copyOnWrite();
      instance.clearPostProcessingAction();
      return this;
    }

    // @@protoc_insertion_point(builder_scope:sensory.api.v1.audio.TranscribeResponse)
  }
  @java.lang.Override
  @java.lang.SuppressWarnings({"unchecked", "fallthrough"})
  protected final java.lang.Object dynamicMethod(
      com.google.protobuf.GeneratedMessageLite.MethodToInvoke method,
      java.lang.Object arg0, java.lang.Object arg1) {
    switch (method) {
      case NEW_MUTABLE_INSTANCE: {
        return new io.sensory.api.v1.audio.TranscribeResponse();
      }
      case NEW_BUILDER: {
        return new Builder();
      }
      case BUILD_MESSAGE_INFO: {
          java.lang.Object[] objects = new java.lang.Object[] {
            "audioEnergy_",
            "transcript_",
            "isPartialResult_",
            "postProcessingAction_",
          };
          java.lang.String info =
              "\u0000\u0004\u0000\u0000\u0001\n\u0004\u0000\u0000\u0000\u0001\u0001\u0002\u0208" +
              "\u0003\u0007\n\t";
          return newMessageInfo(DEFAULT_INSTANCE, info, objects);
      }
      // fall through
      case GET_DEFAULT_INSTANCE: {
        return DEFAULT_INSTANCE;
      }
      case GET_PARSER: {
        com.google.protobuf.Parser<io.sensory.api.v1.audio.TranscribeResponse> parser = PARSER;
        if (parser == null) {
          synchronized (io.sensory.api.v1.audio.TranscribeResponse.class) {
            parser = PARSER;
            if (parser == null) {
              parser =
                  new DefaultInstanceBasedParser<io.sensory.api.v1.audio.TranscribeResponse>(
                      DEFAULT_INSTANCE);
              PARSER = parser;
            }
          }
        }
        return parser;
    }
    case GET_MEMOIZED_IS_INITIALIZED: {
      return (byte) 1;
    }
    case SET_MEMOIZED_IS_INITIALIZED: {
      return null;
    }
    }
    throw new UnsupportedOperationException();
  }


  // @@protoc_insertion_point(class_scope:sensory.api.v1.audio.TranscribeResponse)
  private static final io.sensory.api.v1.audio.TranscribeResponse DEFAULT_INSTANCE;
  static {
    TranscribeResponse defaultInstance = new TranscribeResponse();
    // New instances are implicitly immutable so no need to make
    // immutable.
    DEFAULT_INSTANCE = defaultInstance;
    com.google.protobuf.GeneratedMessageLite.registerDefaultInstance(
      TranscribeResponse.class, defaultInstance);
  }

  public static io.sensory.api.v1.audio.TranscribeResponse getDefaultInstance() {
    return DEFAULT_INSTANCE;
  }

  private static volatile com.google.protobuf.Parser<TranscribeResponse> PARSER;

  public static com.google.protobuf.Parser<TranscribeResponse> parser() {
    return DEFAULT_INSTANCE.getParserForType();
  }
}

