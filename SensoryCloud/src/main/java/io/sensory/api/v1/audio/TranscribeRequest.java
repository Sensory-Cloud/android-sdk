// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: v1/audio/audio.proto

package io.sensory.api.v1.audio;

/**
 * <pre>
 * The top-level message sent by the client for the `Transcribe` method.
 * Multiple `TranscribeRequest` messages are sent in a stream. The first message
 * must contain a `config` message and must not contain `audioContent`.
 * All subsequent messages must contain `audioContent` and
 * must not contain a `config` message.
 * </pre>
 *
 * Protobuf type {@code sensory.api.v1.audio.TranscribeRequest}
 */
public  final class TranscribeRequest extends
    com.google.protobuf.GeneratedMessageLite<
        TranscribeRequest, TranscribeRequest.Builder> implements
    // @@protoc_insertion_point(message_implements:sensory.api.v1.audio.TranscribeRequest)
    TranscribeRequestOrBuilder {
  private TranscribeRequest() {
  }
  private int streamingRequestCase_ = 0;
  private java.lang.Object streamingRequest_;
  public enum StreamingRequestCase {
    CONFIG(1),
    AUDIOCONTENT(2),
    STREAMINGREQUEST_NOT_SET(0);
    private final int value;
    private StreamingRequestCase(int value) {
      this.value = value;
    }
    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static StreamingRequestCase valueOf(int value) {
      return forNumber(value);
    }

    public static StreamingRequestCase forNumber(int value) {
      switch (value) {
        case 1: return CONFIG;
        case 2: return AUDIOCONTENT;
        case 0: return STREAMINGREQUEST_NOT_SET;
        default: return null;
      }
    }
    public int getNumber() {
      return this.value;
    }
  };

  @java.lang.Override
  public StreamingRequestCase
  getStreamingRequestCase() {
    return StreamingRequestCase.forNumber(
        streamingRequestCase_);
  }

  private void clearStreamingRequest() {
    streamingRequestCase_ = 0;
    streamingRequest_ = null;
  }

  public static final int CONFIG_FIELD_NUMBER = 1;
  /**
   * <pre>
   * Provides information that specifies how to process the
   * request. The first `TranscribeRequest` message must contain a
   * `config`  message.
   * </pre>
   *
   * <code>.sensory.api.v1.audio.TranscribeConfig config = 1;</code>
   */
  @java.lang.Override
  public boolean hasConfig() {
    return streamingRequestCase_ == 1;
  }
  /**
   * <pre>
   * Provides information that specifies how to process the
   * request. The first `TranscribeRequest` message must contain a
   * `config`  message.
   * </pre>
   *
   * <code>.sensory.api.v1.audio.TranscribeConfig config = 1;</code>
   */
  @java.lang.Override
  public io.sensory.api.v1.audio.TranscribeConfig getConfig() {
    if (streamingRequestCase_ == 1) {
       return (io.sensory.api.v1.audio.TranscribeConfig) streamingRequest_;
    }
    return io.sensory.api.v1.audio.TranscribeConfig.getDefaultInstance();
  }
  /**
   * <pre>
   * Provides information that specifies how to process the
   * request. The first `TranscribeRequest` message must contain a
   * `config`  message.
   * </pre>
   *
   * <code>.sensory.api.v1.audio.TranscribeConfig config = 1;</code>
   */
  private void setConfig(io.sensory.api.v1.audio.TranscribeConfig value) {
    value.getClass();
  streamingRequest_ = value;
    streamingRequestCase_ = 1;
  }
  /**
   * <pre>
   * Provides information that specifies how to process the
   * request. The first `TranscribeRequest` message must contain a
   * `config`  message.
   * </pre>
   *
   * <code>.sensory.api.v1.audio.TranscribeConfig config = 1;</code>
   */
  private void mergeConfig(io.sensory.api.v1.audio.TranscribeConfig value) {
    value.getClass();
  if (streamingRequestCase_ == 1 &&
        streamingRequest_ != io.sensory.api.v1.audio.TranscribeConfig.getDefaultInstance()) {
      streamingRequest_ = io.sensory.api.v1.audio.TranscribeConfig.newBuilder((io.sensory.api.v1.audio.TranscribeConfig) streamingRequest_)
          .mergeFrom(value).buildPartial();
    } else {
      streamingRequest_ = value;
    }
    streamingRequestCase_ = 1;
  }
  /**
   * <pre>
   * Provides information that specifies how to process the
   * request. The first `TranscribeRequest` message must contain a
   * `config`  message.
   * </pre>
   *
   * <code>.sensory.api.v1.audio.TranscribeConfig config = 1;</code>
   */
  private void clearConfig() {
    if (streamingRequestCase_ == 1) {
      streamingRequestCase_ = 0;
      streamingRequest_ = null;
    }
  }

  public static final int AUDIOCONTENT_FIELD_NUMBER = 2;
  /**
   * <pre>
   * The audio data to be recognized. Sequential chunks of audio data are sent
   * in sequential `TranscribeRequest` messages. The first
   * `TranscribeRequest` message must not contain `audioContent` data
   * and all subsequent `TranscribeRequest` messages must contain
   * `audioContent` data. The audio bytes must be encoded as specified in
   * `TranscribeConfig`.
   * </pre>
   *
   * <code>bytes audioContent = 2;</code>
   * @return Whether the audioContent field is set.
   */
  @java.lang.Override
  public boolean hasAudioContent() {
    return streamingRequestCase_ == 2;
  }
  /**
   * <pre>
   * The audio data to be recognized. Sequential chunks of audio data are sent
   * in sequential `TranscribeRequest` messages. The first
   * `TranscribeRequest` message must not contain `audioContent` data
   * and all subsequent `TranscribeRequest` messages must contain
   * `audioContent` data. The audio bytes must be encoded as specified in
   * `TranscribeConfig`.
   * </pre>
   *
   * <code>bytes audioContent = 2;</code>
   * @return The audioContent.
   */
  @java.lang.Override
  public com.google.protobuf.ByteString getAudioContent() {
    if (streamingRequestCase_ == 2) {
      return (com.google.protobuf.ByteString) streamingRequest_;
    }
    return com.google.protobuf.ByteString.EMPTY;
  }
  /**
   * <pre>
   * The audio data to be recognized. Sequential chunks of audio data are sent
   * in sequential `TranscribeRequest` messages. The first
   * `TranscribeRequest` message must not contain `audioContent` data
   * and all subsequent `TranscribeRequest` messages must contain
   * `audioContent` data. The audio bytes must be encoded as specified in
   * `TranscribeConfig`.
   * </pre>
   *
   * <code>bytes audioContent = 2;</code>
   * @param value The audioContent to set.
   */
  private void setAudioContent(com.google.protobuf.ByteString value) {
    java.lang.Class<?> valueClass = value.getClass();
  streamingRequestCase_ = 2;
    streamingRequest_ = value;
  }
  /**
   * <pre>
   * The audio data to be recognized. Sequential chunks of audio data are sent
   * in sequential `TranscribeRequest` messages. The first
   * `TranscribeRequest` message must not contain `audioContent` data
   * and all subsequent `TranscribeRequest` messages must contain
   * `audioContent` data. The audio bytes must be encoded as specified in
   * `TranscribeConfig`.
   * </pre>
   *
   * <code>bytes audioContent = 2;</code>
   */
  private void clearAudioContent() {
    if (streamingRequestCase_ == 2) {
      streamingRequestCase_ = 0;
      streamingRequest_ = null;
    }
  }

  public static final int POSTPROCESSINGACTION_FIELD_NUMBER = 10;
  private io.sensory.api.v1.audio.AudioRequestPostProcessingAction postProcessingAction_;
  /**
   * <pre>
   * Message used to instruct the audio recognition engine to flush or reset.
   * </pre>
   *
   * <code>.sensory.api.v1.audio.AudioRequestPostProcessingAction postProcessingAction = 10;</code>
   */
  @java.lang.Override
  public boolean hasPostProcessingAction() {
    return postProcessingAction_ != null;
  }
  /**
   * <pre>
   * Message used to instruct the audio recognition engine to flush or reset.
   * </pre>
   *
   * <code>.sensory.api.v1.audio.AudioRequestPostProcessingAction postProcessingAction = 10;</code>
   */
  @java.lang.Override
  public io.sensory.api.v1.audio.AudioRequestPostProcessingAction getPostProcessingAction() {
    return postProcessingAction_ == null ? io.sensory.api.v1.audio.AudioRequestPostProcessingAction.getDefaultInstance() : postProcessingAction_;
  }
  /**
   * <pre>
   * Message used to instruct the audio recognition engine to flush or reset.
   * </pre>
   *
   * <code>.sensory.api.v1.audio.AudioRequestPostProcessingAction postProcessingAction = 10;</code>
   */
  private void setPostProcessingAction(io.sensory.api.v1.audio.AudioRequestPostProcessingAction value) {
    value.getClass();
  postProcessingAction_ = value;
    
    }
  /**
   * <pre>
   * Message used to instruct the audio recognition engine to flush or reset.
   * </pre>
   *
   * <code>.sensory.api.v1.audio.AudioRequestPostProcessingAction postProcessingAction = 10;</code>
   */
  @java.lang.SuppressWarnings({"ReferenceEquality"})
  private void mergePostProcessingAction(io.sensory.api.v1.audio.AudioRequestPostProcessingAction value) {
    value.getClass();
  if (postProcessingAction_ != null &&
        postProcessingAction_ != io.sensory.api.v1.audio.AudioRequestPostProcessingAction.getDefaultInstance()) {
      postProcessingAction_ =
        io.sensory.api.v1.audio.AudioRequestPostProcessingAction.newBuilder(postProcessingAction_).mergeFrom(value).buildPartial();
    } else {
      postProcessingAction_ = value;
    }
    
  }
  /**
   * <pre>
   * Message used to instruct the audio recognition engine to flush or reset.
   * </pre>
   *
   * <code>.sensory.api.v1.audio.AudioRequestPostProcessingAction postProcessingAction = 10;</code>
   */
  private void clearPostProcessingAction() {  postProcessingAction_ = null;
    
  }

  public static io.sensory.api.v1.audio.TranscribeRequest parseFrom(
      java.nio.ByteBuffer data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, data);
  }
  public static io.sensory.api.v1.audio.TranscribeRequest parseFrom(
      java.nio.ByteBuffer data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, data, extensionRegistry);
  }
  public static io.sensory.api.v1.audio.TranscribeRequest parseFrom(
      com.google.protobuf.ByteString data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, data);
  }
  public static io.sensory.api.v1.audio.TranscribeRequest parseFrom(
      com.google.protobuf.ByteString data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, data, extensionRegistry);
  }
  public static io.sensory.api.v1.audio.TranscribeRequest parseFrom(byte[] data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, data);
  }
  public static io.sensory.api.v1.audio.TranscribeRequest parseFrom(
      byte[] data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, data, extensionRegistry);
  }
  public static io.sensory.api.v1.audio.TranscribeRequest parseFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, input);
  }
  public static io.sensory.api.v1.audio.TranscribeRequest parseFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, input, extensionRegistry);
  }
  public static io.sensory.api.v1.audio.TranscribeRequest parseDelimitedFrom(java.io.InputStream input)
      throws java.io.IOException {
    return parseDelimitedFrom(DEFAULT_INSTANCE, input);
  }
  public static io.sensory.api.v1.audio.TranscribeRequest parseDelimitedFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return parseDelimitedFrom(DEFAULT_INSTANCE, input, extensionRegistry);
  }
  public static io.sensory.api.v1.audio.TranscribeRequest parseFrom(
      com.google.protobuf.CodedInputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, input);
  }
  public static io.sensory.api.v1.audio.TranscribeRequest parseFrom(
      com.google.protobuf.CodedInputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, input, extensionRegistry);
  }

  public static Builder newBuilder() {
    return (Builder) DEFAULT_INSTANCE.createBuilder();
  }
  public static Builder newBuilder(io.sensory.api.v1.audio.TranscribeRequest prototype) {
    return (Builder) DEFAULT_INSTANCE.createBuilder(prototype);
  }

  /**
   * <pre>
   * The top-level message sent by the client for the `Transcribe` method.
   * Multiple `TranscribeRequest` messages are sent in a stream. The first message
   * must contain a `config` message and must not contain `audioContent`.
   * All subsequent messages must contain `audioContent` and
   * must not contain a `config` message.
   * </pre>
   *
   * Protobuf type {@code sensory.api.v1.audio.TranscribeRequest}
   */
  public static final class Builder extends
      com.google.protobuf.GeneratedMessageLite.Builder<
        io.sensory.api.v1.audio.TranscribeRequest, Builder> implements
      // @@protoc_insertion_point(builder_implements:sensory.api.v1.audio.TranscribeRequest)
      io.sensory.api.v1.audio.TranscribeRequestOrBuilder {
    // Construct using io.sensory.api.v1.audio.TranscribeRequest.newBuilder()
    private Builder() {
      super(DEFAULT_INSTANCE);
    }

    @java.lang.Override
    public StreamingRequestCase
        getStreamingRequestCase() {
      return instance.getStreamingRequestCase();
    }

    public Builder clearStreamingRequest() {
      copyOnWrite();
      instance.clearStreamingRequest();
      return this;
    }


    /**
     * <pre>
     * Provides information that specifies how to process the
     * request. The first `TranscribeRequest` message must contain a
     * `config`  message.
     * </pre>
     *
     * <code>.sensory.api.v1.audio.TranscribeConfig config = 1;</code>
     */
    @java.lang.Override
    public boolean hasConfig() {
      return instance.hasConfig();
    }
    /**
     * <pre>
     * Provides information that specifies how to process the
     * request. The first `TranscribeRequest` message must contain a
     * `config`  message.
     * </pre>
     *
     * <code>.sensory.api.v1.audio.TranscribeConfig config = 1;</code>
     */
    @java.lang.Override
    public io.sensory.api.v1.audio.TranscribeConfig getConfig() {
      return instance.getConfig();
    }
    /**
     * <pre>
     * Provides information that specifies how to process the
     * request. The first `TranscribeRequest` message must contain a
     * `config`  message.
     * </pre>
     *
     * <code>.sensory.api.v1.audio.TranscribeConfig config = 1;</code>
     */
    public Builder setConfig(io.sensory.api.v1.audio.TranscribeConfig value) {
      copyOnWrite();
      instance.setConfig(value);
      return this;
    }
    /**
     * <pre>
     * Provides information that specifies how to process the
     * request. The first `TranscribeRequest` message must contain a
     * `config`  message.
     * </pre>
     *
     * <code>.sensory.api.v1.audio.TranscribeConfig config = 1;</code>
     */
    public Builder setConfig(
        io.sensory.api.v1.audio.TranscribeConfig.Builder builderForValue) {
      copyOnWrite();
      instance.setConfig(builderForValue.build());
      return this;
    }
    /**
     * <pre>
     * Provides information that specifies how to process the
     * request. The first `TranscribeRequest` message must contain a
     * `config`  message.
     * </pre>
     *
     * <code>.sensory.api.v1.audio.TranscribeConfig config = 1;</code>
     */
    public Builder mergeConfig(io.sensory.api.v1.audio.TranscribeConfig value) {
      copyOnWrite();
      instance.mergeConfig(value);
      return this;
    }
    /**
     * <pre>
     * Provides information that specifies how to process the
     * request. The first `TranscribeRequest` message must contain a
     * `config`  message.
     * </pre>
     *
     * <code>.sensory.api.v1.audio.TranscribeConfig config = 1;</code>
     */
    public Builder clearConfig() {
      copyOnWrite();
      instance.clearConfig();
      return this;
    }

    /**
     * <pre>
     * The audio data to be recognized. Sequential chunks of audio data are sent
     * in sequential `TranscribeRequest` messages. The first
     * `TranscribeRequest` message must not contain `audioContent` data
     * and all subsequent `TranscribeRequest` messages must contain
     * `audioContent` data. The audio bytes must be encoded as specified in
     * `TranscribeConfig`.
     * </pre>
     *
     * <code>bytes audioContent = 2;</code>
     * @return Whether the audioContent field is set.
     */
    @java.lang.Override
    public boolean hasAudioContent() {
      return instance.hasAudioContent();
    }
    /**
     * <pre>
     * The audio data to be recognized. Sequential chunks of audio data are sent
     * in sequential `TranscribeRequest` messages. The first
     * `TranscribeRequest` message must not contain `audioContent` data
     * and all subsequent `TranscribeRequest` messages must contain
     * `audioContent` data. The audio bytes must be encoded as specified in
     * `TranscribeConfig`.
     * </pre>
     *
     * <code>bytes audioContent = 2;</code>
     * @return The audioContent.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString getAudioContent() {
      return instance.getAudioContent();
    }
    /**
     * <pre>
     * The audio data to be recognized. Sequential chunks of audio data are sent
     * in sequential `TranscribeRequest` messages. The first
     * `TranscribeRequest` message must not contain `audioContent` data
     * and all subsequent `TranscribeRequest` messages must contain
     * `audioContent` data. The audio bytes must be encoded as specified in
     * `TranscribeConfig`.
     * </pre>
     *
     * <code>bytes audioContent = 2;</code>
     * @param value The audioContent to set.
     * @return This builder for chaining.
     */
    public Builder setAudioContent(com.google.protobuf.ByteString value) {
      copyOnWrite();
      instance.setAudioContent(value);
      return this;
    }
    /**
     * <pre>
     * The audio data to be recognized. Sequential chunks of audio data are sent
     * in sequential `TranscribeRequest` messages. The first
     * `TranscribeRequest` message must not contain `audioContent` data
     * and all subsequent `TranscribeRequest` messages must contain
     * `audioContent` data. The audio bytes must be encoded as specified in
     * `TranscribeConfig`.
     * </pre>
     *
     * <code>bytes audioContent = 2;</code>
     * @return This builder for chaining.
     */
    public Builder clearAudioContent() {
      copyOnWrite();
      instance.clearAudioContent();
      return this;
    }

    /**
     * <pre>
     * Message used to instruct the audio recognition engine to flush or reset.
     * </pre>
     *
     * <code>.sensory.api.v1.audio.AudioRequestPostProcessingAction postProcessingAction = 10;</code>
     */
    @java.lang.Override
    public boolean hasPostProcessingAction() {
      return instance.hasPostProcessingAction();
    }
    /**
     * <pre>
     * Message used to instruct the audio recognition engine to flush or reset.
     * </pre>
     *
     * <code>.sensory.api.v1.audio.AudioRequestPostProcessingAction postProcessingAction = 10;</code>
     */
    @java.lang.Override
    public io.sensory.api.v1.audio.AudioRequestPostProcessingAction getPostProcessingAction() {
      return instance.getPostProcessingAction();
    }
    /**
     * <pre>
     * Message used to instruct the audio recognition engine to flush or reset.
     * </pre>
     *
     * <code>.sensory.api.v1.audio.AudioRequestPostProcessingAction postProcessingAction = 10;</code>
     */
    public Builder setPostProcessingAction(io.sensory.api.v1.audio.AudioRequestPostProcessingAction value) {
      copyOnWrite();
      instance.setPostProcessingAction(value);
      return this;
      }
    /**
     * <pre>
     * Message used to instruct the audio recognition engine to flush or reset.
     * </pre>
     *
     * <code>.sensory.api.v1.audio.AudioRequestPostProcessingAction postProcessingAction = 10;</code>
     */
    public Builder setPostProcessingAction(
        io.sensory.api.v1.audio.AudioRequestPostProcessingAction.Builder builderForValue) {
      copyOnWrite();
      instance.setPostProcessingAction(builderForValue.build());
      return this;
    }
    /**
     * <pre>
     * Message used to instruct the audio recognition engine to flush or reset.
     * </pre>
     *
     * <code>.sensory.api.v1.audio.AudioRequestPostProcessingAction postProcessingAction = 10;</code>
     */
    public Builder mergePostProcessingAction(io.sensory.api.v1.audio.AudioRequestPostProcessingAction value) {
      copyOnWrite();
      instance.mergePostProcessingAction(value);
      return this;
    }
    /**
     * <pre>
     * Message used to instruct the audio recognition engine to flush or reset.
     * </pre>
     *
     * <code>.sensory.api.v1.audio.AudioRequestPostProcessingAction postProcessingAction = 10;</code>
     */
    public Builder clearPostProcessingAction() {  copyOnWrite();
      instance.clearPostProcessingAction();
      return this;
    }

    // @@protoc_insertion_point(builder_scope:sensory.api.v1.audio.TranscribeRequest)
  }
  @java.lang.Override
  @java.lang.SuppressWarnings({"unchecked", "fallthrough"})
  protected final java.lang.Object dynamicMethod(
      com.google.protobuf.GeneratedMessageLite.MethodToInvoke method,
      java.lang.Object arg0, java.lang.Object arg1) {
    switch (method) {
      case NEW_MUTABLE_INSTANCE: {
        return new io.sensory.api.v1.audio.TranscribeRequest();
      }
      case NEW_BUILDER: {
        return new Builder();
      }
      case BUILD_MESSAGE_INFO: {
          java.lang.Object[] objects = new java.lang.Object[] {
            "streamingRequest_",
            "streamingRequestCase_",
            io.sensory.api.v1.audio.TranscribeConfig.class,
            "postProcessingAction_",
          };
          java.lang.String info =
              "\u0000\u0003\u0001\u0000\u0001\n\u0003\u0000\u0000\u0000\u0001<\u0000\u0002=\u0000" +
              "\n\t";
          return newMessageInfo(DEFAULT_INSTANCE, info, objects);
      }
      // fall through
      case GET_DEFAULT_INSTANCE: {
        return DEFAULT_INSTANCE;
      }
      case GET_PARSER: {
        com.google.protobuf.Parser<io.sensory.api.v1.audio.TranscribeRequest> parser = PARSER;
        if (parser == null) {
          synchronized (io.sensory.api.v1.audio.TranscribeRequest.class) {
            parser = PARSER;
            if (parser == null) {
              parser =
                  new DefaultInstanceBasedParser<io.sensory.api.v1.audio.TranscribeRequest>(
                      DEFAULT_INSTANCE);
              PARSER = parser;
            }
          }
        }
        return parser;
    }
    case GET_MEMOIZED_IS_INITIALIZED: {
      return (byte) 1;
    }
    case SET_MEMOIZED_IS_INITIALIZED: {
      return null;
    }
    }
    throw new UnsupportedOperationException();
  }


  // @@protoc_insertion_point(class_scope:sensory.api.v1.audio.TranscribeRequest)
  private static final io.sensory.api.v1.audio.TranscribeRequest DEFAULT_INSTANCE;
  static {
    TranscribeRequest defaultInstance = new TranscribeRequest();
    // New instances are implicitly immutable so no need to make
    // immutable.
    DEFAULT_INSTANCE = defaultInstance;
    com.google.protobuf.GeneratedMessageLite.registerDefaultInstance(
      TranscribeRequest.class, defaultInstance);
  }

  public static io.sensory.api.v1.audio.TranscribeRequest getDefaultInstance() {
    return DEFAULT_INSTANCE;
  }

  private static volatile com.google.protobuf.Parser<TranscribeRequest> PARSER;

  public static com.google.protobuf.Parser<TranscribeRequest> parser() {
    return DEFAULT_INSTANCE.getParserForType();
  }
}

